{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.99952,
     "end_time": "2025-04-09T16:43:54.166169",
     "exception": false,
     "start_time": "2025-04-09T16:43:53.166649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.004895,
     "end_time": "2025-04-09T16:43:54.176771",
     "exception": false,
     "start_time": "2025-04-09T16:43:54.171876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 6.556611,
     "end_time": "2025-04-09T16:44:00.738571",
     "exception": false,
     "start_time": "2025-04-09T16:43:54.181960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "papermill": {
     "duration": 0.014851,
     "end_time": "2025-04-09T16:44:00.758967",
     "exception": false,
     "start_time": "2025-04-09T16:44:00.744116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 0.013599,
     "end_time": "2025-04-09T16:44:00.777977",
     "exception": false,
     "start_time": "2025-04-09T16:44:00.764378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": 0.038352,
     "end_time": "2025-04-09T16:44:00.821673",
     "exception": false,
     "start_time": "2025-04-09T16:44:00.783321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": 0.037168,
     "end_time": "2025-04-09T16:44:00.864540",
     "exception": false,
     "start_time": "2025-04-09T16:44:00.827372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": 0.887057,
     "end_time": "2025-04-09T16:44:01.757383",
     "exception": false,
     "start_time": "2025-04-09T16:44:00.870326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "papermill": {
     "duration": 0.073261,
     "end_time": "2025-04-09T16:44:01.837138",
     "exception": false,
     "start_time": "2025-04-09T16:44:01.763877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.isnull().any() # No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "papermill": {
     "duration": 0.012485,
     "end_time": "2025-04-09T16:44:01.856099",
     "exception": false,
     "start_time": "2025-04-09T16:44:01.843614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_data.isnull().any() # No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "papermill": {
     "duration": 5.226151,
     "end_time": "2025-04-09T16:44:07.088647",
     "exception": false,
     "start_time": "2025-04-09T16:44:01.862496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the distribution of numerical columns\n",
    "plt.figure(figsize=(12, 10))\n",
    "train_data.hist(bins=50, figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "papermill": {
     "duration": 0.543584,
     "end_time": "2025-04-09T16:44:07.639854",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.096270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No missing values the time serie is complete\n",
    "train_data['timestamp'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "papermill": {
     "duration": 0.007952,
     "end_time": "2025-04-09T16:44:07.656129",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.648177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## corr analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "papermill": {
     "duration": 0.017776,
     "end_time": "2025-04-09T16:44:07.682196",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.664420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Compute correlation matrix\n",
    "corr = train_data.corr()\n",
    "\n",
    "# Plotting the heatmap of correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "papermill": {
     "duration": 0.017111,
     "end_time": "2025-04-09T16:44:07.707771",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.690660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.columns\n",
    "\n",
    "# columns 'open', 'high', 'low', 'close' are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "papermill": {
     "duration": 0.015064,
     "end_time": "2025-04-09T16:44:07.731321",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.716257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pairplot to visualize relationships between numerical columns and target\n",
    "\n",
    "#sns.pairplot(train_data[['open', 'target']])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "papermill": {
     "duration": 0.019286,
     "end_time": "2025-04-09T16:44:07.759523",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.740237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "sns.pairplot(train_data[['volume','quote_asset_volume', \n",
    "                         'number_of_trades', 'taker_buy_base_volume', \n",
    "                         'taker_buy_quote_volume', 'target']])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "papermill": {
     "duration": 0.009675,
     "end_time": "2025-04-09T16:44:07.784329",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.774654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Look at the important features via a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "papermill": {
     "duration": 0.017029,
     "end_time": "2025-04-09T16:44:07.810045",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.793016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Look at the imporatn features\n",
    "# Via gradient boosting\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = train_data.drop(columns=['target', 'timestamp'])\n",
    "y = train_data['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(model, max_num_features=10, importance_type='gain')  # or 'weight', 'cover'\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "papermill": {
     "duration": 0.008358,
     "end_time": "2025-04-09T16:44:07.827271",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.818913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "papermill": {
     "duration": 0.269354,
     "end_time": "2025-04-09T16:44:08.105150",
     "exception": false,
     "start_time": "2025-04-09T16:44:07.835796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the columns with \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 1 Remove the columns  'high', 'low', 'close' (=='open')\n",
    "def preprocess(df):\n",
    "    df.drop(columns=['open', 'high', 'low'], inplace=True)\n",
    "    \n",
    "    # 2 Create new columns based of the timestamp\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['minute'] = df['datetime'].dt.minute\n",
    "    df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "    df['time_since_start'] = (df['datetime'] - df['datetime'].min()).dt.total_seconds()\n",
    "    df.drop(columns=['datetime', 'timestamp'], inplace=True)\n",
    "\n",
    "    # 3 Lets add normlization for each columns \n",
    "    num_columns = ['close', 'volume', 'quote_asset_volume', 'number_of_trades',\n",
    "       'taker_buy_base_volume', 'taker_buy_quote_volume', 'hour',\n",
    "       'minute', 'dayofweek', 'time_since_start']\n",
    "    scaler = StandardScaler()\n",
    "    df[num_columns] = scaler.fit_transform(df[num_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "papermill": {
     "duration": 0.009072,
     "end_time": "2025-04-09T16:44:08.129488",
     "exception": false,
     "start_time": "2025-04-09T16:44:08.120416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "papermill": {
     "duration": 0.008206,
     "end_time": "2025-04-09T16:44:08.146406",
     "exception": false,
     "start_time": "2025-04-09T16:44:08.138200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "papermill": {
     "duration": 0.016799,
     "end_time": "2025-04-09T16:44:08.171651",
     "exception": false,
     "start_time": "2025-04-09T16:44:08.154852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE very bad\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/test.csv')\n",
    "\n",
    "# Preprocess the data (assuming the preprocessing function is defined)\n",
    "train_df = preprocess(train_data)\n",
    "\n",
    "# Select features and target\n",
    "X = train_df.drop(columns=['target', 'timestamp'])  # Features (excluding target and timestamp)\n",
    "y = train_data['target']  # Target variable\n",
    "\n",
    "# Train-test split (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Convert predictions to binary (0 or 1) since Linear Regression gives continuous outputs\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Assuming the threshold for binary classification is 0.5\n",
    "\n",
    "# Evaluate using F1-score\n",
    "f1 = f1_score(y_val, y_pred_binary)\n",
    "print(f\"F1-Score (Linear Regression): {f1:.4f}\")\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "papermill": {
     "duration": 0.008198,
     "end_time": "2025-04-09T16:44:08.188605",
     "exception": false,
     "start_time": "2025-04-09T16:44:08.180407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "papermill": {
     "duration": 0.018086,
     "end_time": "2025-04-09T16:44:08.215252",
     "exception": false,
     "start_time": "2025-04-09T16:44:08.197166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Preprocess the data \n",
    "train_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/train.csv')\n",
    "\n",
    "train_df = preprocess(train_data).copy()\n",
    "\n",
    "\n",
    "# Assuming `train_data` is your dataset\n",
    "X = train_df.drop(columns=['target'])  # Features (excluding target and timestamp)\n",
    "y = train_data['target']  # Target variable\n",
    "\n",
    "\n",
    "# Train-test split (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize XGBoost model\n",
    "model = xgb.XGBClassifier(n_estimators=500, \n",
    "                          max_depth=15, \n",
    "                          random_state=42, \n",
    "                          scale_pos_weight=1)\n",
    "\n",
    "# Fit model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate using F1-score\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "print(f\"F1-Score (XGBoost): {f1:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "papermill": {
     "duration": 109.379002,
     "end_time": "2025-04-09T16:45:57.603323",
     "exception": false,
     "start_time": "2025-04-09T16:44:08.224321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model with full dataset and predict the \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Preprocess the data \n",
    "train_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/train.csv')\n",
    "\n",
    "train_df = preprocess(train_data)\n",
    "\n",
    "# Assuming `train_data` is your dataset\n",
    "X = train_df.drop(columns=['target'])  # Features (excluding target and timestamp)\n",
    "y = train_data['target'] \n",
    "\n",
    "# Initialize XGBoost model\n",
    "model = xgb.XGBClassifier(n_estimators=500, \n",
    "                          max_depth=15, \n",
    "                          random_state=42, \n",
    "                          scale_pos_weight=1)\n",
    "\n",
    "# Fit model on training data\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# Inference part\n",
    "test_data = pd.read_csv('/kaggle/input/directional-forecasting-in-cryptocurrencies/test.csv')\n",
    "test_df = preprocess(test_data)\n",
    "\n",
    "X_test = test_df.drop(columns=['row_id'])\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Save model and perform inference\n",
    "output = pd.DataFrame({\n",
    "    'row_id': test_data['row_id'],\n",
    "    'target': y_test\n",
    "})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print('model saved')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9630059,
     "sourceId": 85340,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 128.045864,
   "end_time": "2025-04-09T16:45:58.434007",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-09T16:43:50.388143",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
